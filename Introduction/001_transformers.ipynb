{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifer = pipeline(\"sentiment-analysis\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998793601989746}, {'label': 'POSITIVE', 'score': 0.9997734427452087}]\n"
     ]
    }
   ],
   "source": [
    "# classifer(\"I'm sad\")\n",
    "\n",
    "print(classifer([\"I'm happy\",\n",
    "           \"I'm so excited to code\",\n",
    "\n",
    "           ]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to roberta-large-mnli and revision 130fb28 (https://huggingface.co/roberta-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'sequence': 'This is sample for test',\n 'labels': ['task', 'haha', 'game', 'business'],\n 'scores': [0.8454039096832275,\n  0.06346133351325989,\n  0.05966110900044441,\n  0.03147362917661667]}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zeroshot classification\n",
    "classifer_zeroshot = pipeline(\"zero-shot-classification\")\n",
    "classifer_zeroshot(\"This is sample for test\",\n",
    "                   candidate_labels=[\"task\", \"haha\", \"game\", \"business\"]\n",
    "                   )\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/Users/hotronghai/Documents/Hai-Source/HuggingFace/venv/lib/python3.8/site-packages/transformers/generation/tf_utils.py:854: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'generated_text': 'Hello, how are you doing? Thank you. I love to do this, really. When did you start looking for an appointment...\\n\\n[He and Gellert are sitting on the sofa, smiling. \"I was wondering what the big'}]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text generation\n",
    "generator = pipeline('text-generation')\n",
    "generator(\"Hello, how are you\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the weights of TFRobertaForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[[{'score': 0.5512077212333679,\n   'token': 89,\n   'token_str': ' there',\n   'sequence': \"<s>Hello there are you. I'm fine.<mask> you</s>\"},\n  {'score': 0.10521949827671051,\n   'token': 259,\n   'token_str': ' here',\n   'sequence': \"<s>Hello here are you. I'm fine.<mask> you</s>\"},\n  {'score': 0.07069817930459976,\n   'token': 47,\n   'token_str': ' you',\n   'sequence': \"<s>Hello you are you. I'm fine.<mask> you</s>\"},\n  {'score': 0.02468958869576454,\n   'token': 6,\n   'token_str': ',',\n   'sequence': \"<s>Hello, are you. I'm fine.<mask> you</s>\"},\n  {'score': 0.02163885161280632,\n   'token': 141,\n   'token_str': ' how',\n   'sequence': \"<s>Hello how are you. I'm fine.<mask> you</s>\"}],\n [{'score': 0.9021763205528259,\n   'token': 3837,\n   'token_str': ' Thank',\n   'sequence': \"<s>Hello<mask> are you. I'm fine. Thank you</s>\"},\n  {'score': 0.04290628805756569,\n   'token': 4250,\n   'token_str': ' See',\n   'sequence': \"<s>Hello<mask> are you. I'm fine. See you</s>\"},\n  {'score': 0.03326594457030296,\n   'token': 3437,\n   'token_str': ' Love',\n   'sequence': \"<s>Hello<mask> are you. I'm fine. Love you</s>\"},\n  {'score': 0.003401981433853507,\n   'token': 3392,\n   'token_str': ' thank',\n   'sequence': \"<s>Hello<mask> are you. I'm fine. thank you</s>\"},\n  {'score': 0.002538773464038968,\n   'token': 36183,\n   'token_str': ' Bless',\n   'sequence': \"<s>Hello<mask> are you. I'm fine. Bless you</s>\"}]]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill-mask\n",
    "from transformers import pipeline\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"Hello <mask> are you. I'm fine. <mask> you\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carpenter', 'lawyer', 'farmer', 'businessman', 'doctor']\n",
      "['nurse', 'maid', 'teacher', 'waitress', 'prostitute']\n"
     ]
    }
   ],
   "source": [
    "# Bias and limitations\n",
    "from transformers import pipeline\n",
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "result = unmasker(\"This man works as a [MASK].\")\n",
    "\n",
    "print([r[\"token_str\"] for r in result])\n",
    "\n",
    "result = unmasker(\"This woman works as a [MASK].\")\n",
    "print([r[\"token_str\"] for r in result])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}